#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
XGBoost Model - NBA Predictions FIXED
Train/Test Split + Filtres de stabilit√©
"""

import numpy as np
import pandas as pd
import joblib
from pathlib import Path
from datetime import datetime

from xgboost import XGBRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

from advanced_data_collector import AdvancedDataCollector


class XGBoostNBAModel:
    """
    Mod√®le XGBoost avec validation chronologique
    """
    
    def __init__(self, stat_type='points'):
        self.stat_type = stat_type
        self.stat_col = {'points': 'PTS', 'assists': 'AST', 'rebounds': 'REB'}[stat_type]
        
        self.model = None
        self.scaler = StandardScaler()
        self.feature_names = []
        self.training_stats = {}
        
        # Hyperparam√®tres ANTI-OVERFITTING
        self.model_params = {
            'n_estimators': 300,      # R√©duit de 500
            'learning_rate': 0.05,
            'max_depth': 4,           # R√©duit de 6 ‚Üí √©vite m√©morisation
            'min_child_weight': 5,    # Augment√© de 3 ‚Üí moins de splits
            'subsample': 0.7,         # R√©duit de 0.8
            'colsample_bytree': 0.7,  # R√©duit de 0.8
            'gamma': 0.3,             # Augment√© de 0.1 ‚Üí p√©nalise splits
            'reg_alpha': 0.5,         # Augment√© de 0.1 ‚Üí L1 regularization
            'reg_lambda': 2.0,        # Augment√© de 1.0 ‚Üí L2 regularization
            'random_state': 42,
            'n_jobs': -1
        }
    
    def train(self, player_name, season='2024-25', save_model=True):
        """
        Entra√Æne avec TRAIN/TEST SPLIT chronologique
        """
        
        print(f"\n{'='*70}")
        print(f"ü§ñ XGBOOST - {player_name} ({self.stat_type.upper()})")
        print(f"{'='*70}\n")
        
        # 1. Collecte donn√©es
        collector = AdvancedDataCollector()
        df = collector.get_complete_player_data(player_name, season)
        
        if df is None or len(df) < 15:
            return {'status': 'ERROR', 'message': 'Pas assez de donn√©es (min 15 matchs)'}
        
        # 2. Pr√©pare features
        X, y, feature_names = self._prepare_training_data(df)
        
        if X is None:
            return {'status': 'ERROR', 'message': 'Erreur pr√©paration'}
        
        self.feature_names = feature_names
        
        print(f"üìä Total: {len(X)} matchs, {len(feature_names)} features")
        print(f"üìä {self.stat_col}: moyenne={y.mean():.1f}, std={y.std():.1f}\n")
        
        # ‚úÖ 3. SPLIT CHRONOLOGIQUE (80% train, 20% test)
        split_idx = int(len(X) * 0.8)
        
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        print(f"‚úÖ Train: {len(X_train)} matchs (anciens)")
        print(f"‚úÖ Test: {len(X_test)} matchs (r√©cents - JAMAIS VUS!)\n")
        
        # 4. Standardisation (fit sur train SEULEMENT!)
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # 5. Cross-validation sur train
        print("üîÑ Cross-Validation (TimeSeriesSplit)...")
        cv_results = self._cross_validate(X_train_scaled, y_train)
        
        # 6. Entra√Ænement final (sur train SEULEMENT!)
        print("\nü§ñ Entra√Ænement final (sur train set)...")
        self.model = XGBRegressor(**self.model_params)
        self.model.fit(X_train_scaled, y_train, verbose=False)
        
        # ‚úÖ 7. √âVALUATION SUR TEST SET (MATCHS FUTURS JAMAIS VUS!)
        print("\nüéØ √âVALUATION SUR MATCHS FUTURS (test set)...")
        y_pred_test = self.model.predict(X_test_scaled)
        
        test_r2 = r2_score(y_test, y_pred_test)
        test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
        test_mae = mean_absolute_error(y_test, y_pred_test)
        
        # Calcule stabilit√© (coefficient de variation)
        cv_percent = (y.std() / y.mean()) * 100 if y.mean() > 0 else 100
        
        print(f"  R¬≤ TEST: {test_r2:.3f} ‚Üê VRAI R¬≤!")
        print(f"  RMSE TEST: {test_rmse:.2f}")
        print(f"  MAE TEST: {test_mae:.2f}")
        print(f"  Stabilit√©: CV = {cv_percent:.1f}% (plus bas = mieux)")
        
        # Train metrics (pour comparaison)
        y_pred_train = self.model.predict(X_train_scaled)
        train_r2 = r2_score(y_train, y_pred_train)
        train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
        
        print(f"\nüìä COMPARAISON:")
        print(f"  Train R¬≤: {train_r2:.3f} (si >> test R¬≤ = overfit!)")
        print(f"  Test R¬≤: {test_r2:.3f} (VRAI performance)")
        
        if train_r2 - test_r2 > 0.15:
            print(f"  ‚ö†Ô∏è  OVERFIT d√©tect√©! Diff√©rence = {train_r2 - test_r2:.3f}")
        
        # 8. Sauvegarde
        if save_model:
            self._save_model(player_name, season)
        
        # R√©sultats
        results = {
            'status': 'SUCCESS',
            'player': player_name,
            'stat_type': self.stat_type,
            'training_samples': len(X_train),
            'test_samples': len(X_test),
            'cv_results': cv_results,
            'test_metrics': {  # ‚Üê VRAIES M√âTRIQUES!
                'r2': float(test_r2),
                'rmse': float(test_rmse),
                'mae': float(test_mae)
            },
            'train_metrics': {  # Pour comparaison
                'r2': float(train_r2),
                'rmse': float(train_rmse)
            },
            'stability': {
                'mean': float(y.mean()),
                'std': float(y.std()),
                'cv_percent': float(cv_percent),
                'min': float(y.min()),
                'max': float(y.max())
            },
            'model_saved': save_model
        }
        
        self.training_stats = results
        
        print(f"\n{'='*70}\n")
        
        return results
    
    def _prepare_training_data(self, df):
        """Pr√©pare X et y"""
        
        exclude_cols = [
            'GAME_DATE', 'MATCHUP', 'WL', 'opponent',
            'PTS', 'AST', 'REB', 'FGM', 'FGA', 
            'FG3M', 'FG3A', 'FTM', 'FTA', 'STL', 'BLK', 'TOV'
        ]
        
        feature_cols = [col for col in df.columns if col not in exclude_cols]
        df_clean = df[feature_cols + [self.stat_col]].dropna()
        
        if len(df_clean) < 10:
            return None, None, None
        
        X = df_clean[feature_cols].values
        y = df_clean[self.stat_col].values
        
        return X, y, feature_cols
    
    def _cross_validate(self, X, y, n_splits=5):
        """Cross-validation temporelle"""
        
        tscv = TimeSeriesSplit(n_splits=n_splits)
        
        r2_scores = []
        rmse_scores = []
        
        for fold, (train_idx, val_idx) in enumerate(tscv.split(X)):
            X_tr, X_val = X[train_idx], X[val_idx]
            y_tr, y_val = y[train_idx], y[val_idx]
            
            model_fold = XGBRegressor(**self.model_params)
            model_fold.fit(X_tr, y_tr, verbose=False)
            
            y_pred = model_fold.predict(X_val)
            r2 = r2_score(y_val, y_pred)
            rmse = np.sqrt(mean_squared_error(y_val, y_pred))
            
            r2_scores.append(r2)
            rmse_scores.append(rmse)
            
            print(f"  Fold {fold+1}/{n_splits}: R¬≤={r2:.3f}, RMSE={rmse:.2f}")
        
        cv_results = {
            'r2_mean': float(np.mean(r2_scores)),
            'r2_std': float(np.std(r2_scores)),
            'rmse_mean': float(np.mean(rmse_scores)),
            'rmse_std': float(np.std(rmse_scores))
        }
        
        print(f"\n  CV Moyenne: R¬≤={cv_results['r2_mean']:.3f} (¬±{cv_results['r2_std']:.3f})")
        print(f"              RMSE={cv_results['rmse_mean']:.2f} (¬±{cv_results['rmse_std']:.2f})")
        
        return cv_results
    
    def predict(self, features_dict):
        """Pr√©diction avec intervalle bas√© sur TEST RMSE"""
        
        if self.model is None:
            return {'error': 'Model not trained'}
        
        feature_vector = [features_dict.get(fname, 0) for fname in self.feature_names]
        feature_vector = np.array(feature_vector).reshape(1, -1)
        feature_vector_scaled = self.scaler.transform(feature_vector)
        
        prediction = self.model.predict(feature_vector_scaled)[0]
        
        # ‚úÖ Intervalle bas√© sur TEST RMSE (pas train!)
        test_rmse = self.training_stats.get('test_metrics', {}).get('rmse', 5.0)
        margin = 1.96 * test_rmse
        
        return {
            'prediction': round(float(prediction), 1),
            'confidence_interval': {
                'lower': round(float(prediction - margin), 1),
                'upper': round(float(prediction + margin), 1),
                'width': round(float(2 * margin), 1)
            },
            'model_type': 'XGBoost',
            'test_r2': self.training_stats.get('test_metrics', {}).get('r2', 0.0)
        }
    
    def _save_model(self, player_name, season):
        """Sauvegarde"""
        
        models_dir = Path('models')
        models_dir.mkdir(exist_ok=True)
        
        player_slug = player_name.lower().replace(' ', '_')
        model_path = models_dir / f"{player_slug}_{self.stat_type}_{season}.pkl"
        
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'feature_names': self.feature_names,
            'stat_type': self.stat_type,
            'player': player_name,
            'season': season,
            'training_stats': self.training_stats
        }
        
        joblib.dump(model_data, model_path)
        print(f"üíæ Sauvegard√©: {model_path}")
    
    @classmethod
    def load_model(cls, model_path):
        """Charge un mod√®le"""
        
        model_data = joblib.load(model_path)
        instance = cls(stat_type=model_data['stat_type'])
        instance.model = model_data['model']
        instance.scaler = model_data['scaler']
        instance.feature_names = model_data['feature_names']
        instance.training_stats = model_data['training_stats']
        
        return instance
# ============================================================================
# MODEL MANAGER - Avec filtres de stabilit√©
# ============================================================================

class ModelManager:
    """
    G√®re les mod√®les avec FILTRES DE QUALIT√â
    """
    
    def __init__(self):
        self.models = {}
        self.models_dir = Path('models')
        self.models_dir.mkdir(exist_ok=True)
    
    def train_player_all_stats(self, player_name, season='2024-25'):
        """
        Entra√Æne les 3 mod√®les avec validation
        """
        
        print(f"\n{'='*70}")
        print(f"üéØ ENTRA√éNEMENT COMPLET: {player_name}")
        print(f"{'='*70}\n")
        
        results = {}
        
        for stat_type in ['points', 'assists', 'rebounds']:
            print(f"\n--- {stat_type.upper()} ---")
            
            model = XGBoostNBAModel(stat_type=stat_type)
            result = model.train(player_name, season, save_model=True)
            
            if result['status'] == 'SUCCESS':
                # ‚úÖ Filtre de qualit√©
                test_r2 = result['test_metrics']['r2']
                cv_percent = result['stability']['cv_percent']
                
                print(f"\nüìä QUALIT√â DU MOD√àLE:")
                print(f"  Test R¬≤: {test_r2:.3f}")
                print(f"  Stabilit√© (CV%): {cv_percent:.1f}%")
                
                # √âvaluation
                if test_r2 >= 0.70:
                    quality = "üü¢ EXCELLENT"
                elif test_r2 >= 0.50:
                    quality = "üü° BON"
                elif test_r2 >= 0.30:
                    quality = "üü† MOYEN"
                else:
                    quality = "üî¥ FAIBLE - NE PAS UTILISER!"
                
                if cv_percent > 40:
                    quality += " - ‚ö†Ô∏è TR√àS INSTABLE!"
                
                print(f"  √âvaluation: {quality}\n")
                
                key = f"{player_name}_{stat_type}"
                self.models[key] = model
                results[stat_type] = result
            else:
                print(f"‚ùå √âchec {stat_type}\n")
        
        return results
    
    def load_player_models(self, player_name, season='2024-25'):
        """Charge les mod√®les d'un joueur"""
        
        player_slug = player_name.lower().replace(' ', '_')
        
        for stat_type in ['points', 'assists', 'rebounds']:
            model_path = self.models_dir / f"{player_slug}_{stat_type}_{season}.pkl"
            
            if model_path.exists():
                try:
                    model = XGBoostNBAModel.load_model(model_path)
                    key = f"{player_name}_{stat_type}"
                    self.models[key] = model
                    
                    # Affiche qualit√© du mod√®le charg√©
                    test_r2 = model.training_stats.get('test_metrics', {}).get('r2', 0)
                    print(f"‚úÖ {stat_type}: R¬≤={test_r2:.3f}")
                except Exception as e:
                    print(f"‚ùå Erreur {stat_type}: {e}")
    
    def predict(self, player_name, stat_type, opponent, is_home, season='2024-25'):
        """
        Fait une pr√©diction avec VALIDATION DE QUALIT√â
        """
        
        key = f"{player_name}_{stat_type}"
        
        # Charge ou entra√Æne le mod√®le
        if key not in self.models:
            print(f"‚ö†Ô∏è  Mod√®le non trouv√©, entra√Ænement...")
            model = XGBoostNBAModel(stat_type=stat_type)
            result = model.train(player_name, season)
            
            if result['status'] == 'SUCCESS':
                self.models[key] = model
            else:
                return {'error': 'Unable to train model'}
        
        model = self.models[key]
        
        # ‚úÖ V√âRIFIE LA QUALIT√â DU MOD√àLE
        test_r2 = model.training_stats.get('test_metrics', {}).get('r2', 0)
        cv_percent = model.training_stats.get('stability', {}).get('cv_percent', 100)
        
        # Pr√©pare features
        collector = AdvancedDataCollector()
        features = collector.prepare_features_for_prediction(
            player_name, opponent, is_home, season
        )
        
        if features is None:
            return {'error': 'Unable to prepare features'}
        
        # Pr√©diction
        prediction_result = model.predict(features)
        
        # ‚úÖ AJOUTE M√âTRIQUES DE QUALIT√â
        prediction_result['quality_metrics'] = {
            'test_r2': round(test_r2, 3),
            'stability_cv': round(cv_percent, 1),
            'recommendation': self._get_recommendation(test_r2, cv_percent)
        }
        
        return prediction_result
    
    def _get_recommendation(self, test_r2, cv_percent):
        """
        Recommandation bas√©e sur R¬≤ ET stabilit√©
        """
        
        if test_r2 >= 0.70 and cv_percent <= 25:
            return "üü¢ EXCELLENT - Haute confiance"
        elif test_r2 >= 0.70 and cv_percent <= 35:
            return "üü¢ BON - Confiance √©lev√©e mais variance mod√©r√©e"
        elif test_r2 >= 0.50 and cv_percent <= 30:
            return "üü° CORRECT - Confiance moyenne"
        elif test_r2 >= 0.50 and cv_percent <= 40:
            return "üü° MOYEN - Confiance moyenne, haute variance"
        elif test_r2 >= 0.30:
            return "üü† FAIBLE - Utiliser avec pr√©caution"
        else:
            return "üî¥ TR√àS FAIBLE - NE PAS PARIER!"
    
    def get_betting_opportunities(self, min_test_r2=0.70, max_cv_percent=30):
        """
        Retourne seulement les opportunit√©s avec mod√®les de QUALIT√â
        
        Args:
            min_test_r2: R¬≤ minimum sur test set (d√©faut: 0.70 = 70%)
            max_cv_percent: CV% maximum (d√©faut: 30% de variance)
        """
        
        quality_models = {}
        
        for key, model in self.models.items():
            test_r2 = model.training_stats.get('test_metrics', {}).get('r2', 0)
            cv_percent = model.training_stats.get('stability', {}).get('cv_percent', 100)
            
            if test_r2 >= min_test_r2 and cv_percent <= max_cv_percent:
                quality_models[key] = {
                    'model': model,
                    'test_r2': test_r2,
                    'cv_percent': cv_percent,
                    'player': model.training_stats.get('player'),
                    'stat_type': model.stat_type
                }
        
        return quality_models


# ============================================================================
# FILTRES RECOMMAND√âS
# ============================================================================

class BettingFilters:
    """
    Filtres pour s√©lectionner les MEILLEURS paris
    """
    
    @staticmethod
    def filter_high_quality(opportunities, min_test_r2=0.70, max_cv=30):
        """
        Filtre STRICT: R¬≤ ‚â• 70% ET CV ‚â§ 30%
        
        R√©sultat: ~20-30% des opportunit√©s mais HAUTE QUALIT√â
        """
        
        filtered = []
        
        for opp in opportunities:
            test_r2 = opp.get('regression_stats', {}).get('r2', 0)
            
            # Note: Tu dois ajouter CV dans le backend
            # Pour l'instant, on filtre juste sur R¬≤
            
            if test_r2 >= min_test_r2:
                filtered.append(opp)
        
        return filtered
    
    @staticmethod
    def filter_medium_quality(opportunities, min_test_r2=0.50, max_cv=40):
        """
        Filtre MOD√âR√â: R¬≤ ‚â• 50% ET CV ‚â§ 40%
        
        R√©sultat: ~50% des opportunit√©s, qualit√© moyenne
        """
        
        filtered = []
        
        for opp in opportunities:
            test_r2 = opp.get('regression_stats', {}).get('r2', 0)
            
            if test_r2 >= min_test_r2:
                filtered.append(opp)
        
        return filtered


# ============================================================================
# TEST
# ============================================================================

if __name__ == '__main__':
    
    print("\n" + "="*70)
    print("üß™ TEST: ENTRA√éNEMENT AVEC VALIDATION")
    print("="*70)
    
    # Test sur un joueur STABLE
    player_stable = "LeBron James"
    
    print(f"\nüî¨ Test 1: Joueur STABLE ({player_stable})")
    print("="*70)
    
    model = XGBoostNBAModel(stat_type='points')
    results = model.train(player_stable, '2024-25', save_model=True)
    
    if results['status'] == 'SUCCESS':
        test_r2 = results['test_metrics']['r2']
        cv_percent = results['stability']['cv_percent']
        
        print(f"\nüéØ R√âSULTATS:")
        print(f"  Test R¬≤: {test_r2:.3f}")
        print(f"  Stabilit√© CV: {cv_percent:.1f}%")
        
        if test_r2 >= 0.70 and cv_percent <= 30:
            print(f"  ‚úÖ EXCELLENT MOD√àLE - Recommand√© pour paris!")
        elif test_r2 >= 0.50:
            print(f"  üü° MOD√àLE MOYEN - Utiliser avec pr√©caution")
        else:
            print(f"  ‚ùå MOD√àLE FAIBLE - Ne pas parier!")
    
    # Test sur un joueur INSTABLE
    player_unstable = "Ausar Thompson"
    
    print(f"\n\nüî¨ Test 2: Joueur INSTABLE ({player_unstable})")
    print("="*70)
    
    model2 = XGBoostNBAModel(stat_type='points')
    results2 = model2.train(player_unstable, '2024-25', save_model=False)
    
    if results2['status'] == 'SUCCESS':
        test_r2 = results2['test_metrics']['r2']
        cv_percent = results2['stability']['cv_percent']
        
        print(f"\nüéØ R√âSULTATS:")
        print(f"  Test R¬≤: {test_r2:.3f}")
        print(f"  Stabilit√© CV: {cv_percent:.1f}%")
        
        if test_r2 >= 0.70 and cv_percent <= 30:
            print(f"  ‚úÖ EXCELLENT - Recommand√©")
        elif test_r2 >= 0.50:
            print(f"  üü° MOYEN - Pr√©caution")
        else:
            print(f"  ‚ùå FAIBLE - NE PAS PARIER!")
        
        if cv_percent > 40:
            print(f"  ‚ö†Ô∏è  TROP INSTABLE! Variance = {cv_percent:.1f}%")
    
    print("\n" + "="*70 + "\n")